{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_task.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ekHXc2EiqBYf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "cea7b989-252c-4c6d-bb2a-832a0b093ee9"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/colab')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DloIGjxwqIGd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp -r \"/colab/My Drive/Vision_task_dataset_public\" \"./\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PqqvYKRmqroV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "brsIrKAzrJzP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('Vision_task_dataset_public/train_image.pkl', 'rb') as file:\n",
        "    train_data = pickle.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bC3o_poprTr_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14d735f3-565f-4f6e-d4c3-611d8c5ca864"
      },
      "cell_type": "code",
      "source": [
        "print(type(train_data),len(train_data))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'> 8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FsQ6EHkJrmH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "f71862e3-6279-4f9f-f5bf-c83957422a43"
      },
      "cell_type": "code",
      "source": [
        "x = np.array(train_data[0]).reshape(28,28)\n",
        "plt.imshow(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9701030f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "xpRYu-7vum9j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = np.array(train_data).reshape(8000,28,28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LNi9b6bEswSF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('Vision_task_dataset_public/train_label.pkl', 'rb') as file:\n",
        "    train_label = pickle.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RdnhoD0wtFVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62d55cc3-948a-41b6-852f-3ca905a634b2"
      },
      "cell_type": "code",
      "source": [
        "np.unique(train_label,return_counts=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 2, 3, 6]), array([2000, 2000, 2000, 2000]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "1w3paZgK5zh-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_labels = np.array(train_label).reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dNsBIvxR1xFj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9e883143-f69f-436e-c84d-56024f1fd8d6"
      },
      "cell_type": "code",
      "source": [
        "enc = OneHotEncoder(handle_unknown='ignore',sparse=True)\n",
        "train_labels = enc.fit_transform(train_labels).toarray()\n",
        "print(train_labels.shape)\n",
        "enc.categories_"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 2, 3, 6])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "5ZHWae7qt0ag",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = np.reshape(train_data,(-1,28,28,1))\n",
        "x_train,x_val,y_train,y_val = tts(train_data,train_labels,random_state = 5,test_size = 0.1,shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QX5HgQ6Cx23i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "74d947b7-efcb-4b8f-c493-e32feeea44fa"
      },
      "cell_type": "code",
      "source": [
        "M = np.float32([[1, 0, 5], [0, 1, 5]])\n",
        "for i in tqdm(range(len(x_train))):\n",
        "  x = x_train[i]\n",
        "  x=x.astype(np.float32)\n",
        "  y = y_train[i].reshape(1,4)\n",
        "  x1 = np.fliplr(x).reshape(1,28,28,1)\n",
        "  x2 = np.flipud(x).reshape(1,28,28,1)\n",
        "  x3 = np.rot90(x).reshape(1,28,28,1)\n",
        "  x4 = cv2.warpAffine(x, M, (28, 28))\n",
        "  x5 = np.flipud(x4).reshape(1,28,28,1)\n",
        "  x4 = x4.reshape(1,28,28,1)\n",
        "  x_train = np.concatenate((x_train,x2),axis=0)\n",
        "  x_train = np.concatenate((x_train,x3),axis=0)\n",
        "  x_train = np.concatenate((x_train,x1),axis=0)\n",
        "  x_train = np.concatenate((x_train,x4),axis=0)\n",
        "  x_train = np.concatenate((x_train,x5),axis=0)\n",
        "  for j in range(5):\n",
        "    y_train = np.concatenate((y_train,y),axis=0)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 7200/7200 [20:00<00:00,  3.51it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FXzfE5EqQZRx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mean = 0\n",
        "var = 0.1\n",
        "sigma = var**0.5\n",
        "for i in range(500):\n",
        "  gauss = np.random.normal(mean,sigma,(28,28,1)).reshape(1,28,28,1)\n",
        "  y = y_train[456+i].reshape(1,4)\n",
        "  x_train = np.concatenate((x_train,gauss),axis=0)\n",
        "  y_train = np.concatenate((y_train,y),axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FmhU3Jp6Xz-G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train = shuffle(x_train, y_train, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jkCf8RUDb_YF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d71360a8-da6e-4552-8352-82ef8ef4c606"
      },
      "cell_type": "code",
      "source": [
        "x_train.shape,y_train.shape,x_val.shape,y_val.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((44200, 28, 28, 1), (44200, 4), (800, 28, 28, 1), (800, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "5rBqwMHUuajP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Dense, Flatten, Convolution2D, Activation, BatchNormalization, MaxPool2D\n",
        "from keras.layers.advanced_activations import LeakyReLU, PReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3-79Yf20-bT1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "82bd3874-fafb-4776-a3c6-8ed037989508"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(16, (3,3), padding='same', use_bias=False, input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "# model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(LeakyReLU(alpha=0.1))\n",
        "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "# model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "# model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "# model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "# model.add(Convolution2D(512, (3,3), use_bias=False))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(LeakyReLU(alpha=0.1))\n",
        "\n",
        "model.add(Convolution2D(64, (3,3), use_bias=False))\n",
        "model.add(BatchNormalization())\n",
        "model.add(LeakyReLU(alpha=0.1))\n",
        "          \n",
        "model.add(Flatten())\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(4,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 16)        144       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 28, 28, 16)        64        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 16)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 14, 14, 32)        4608      \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 14, 14, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 5, 5, 64)          18432     \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 5, 5, 64)          256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 100)               160100    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 4)                 404       \n",
            "=================================================================\n",
            "Total params: 184,136\n",
            "Trainable params: 183,912\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zdwXucWd_KI0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3U_qfnZg_dtW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1700
        },
        "outputId": "2dd48d31-54b7-4f48-e932-6ab6c641ef2e"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,batch_size=64,epochs=50,validation_data=(x_val,y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 44200 samples, validate on 800 samples\n",
            "Epoch 1/50\n",
            "44200/44200 [==============================] - 9s 214us/step - loss: 0.6078 - acc: 0.7498 - val_loss: 0.3958 - val_acc: 0.8575\n",
            "Epoch 2/50\n",
            "44200/44200 [==============================] - 9s 197us/step - loss: 0.4575 - acc: 0.8167 - val_loss: 0.3969 - val_acc: 0.8350\n",
            "Epoch 3/50\n",
            "44200/44200 [==============================] - 9s 203us/step - loss: 0.4000 - acc: 0.8398 - val_loss: 0.4915 - val_acc: 0.8012\n",
            "Epoch 4/50\n",
            "44200/44200 [==============================] - 9s 195us/step - loss: 0.3625 - acc: 0.8524 - val_loss: 0.4143 - val_acc: 0.8512\n",
            "Epoch 5/50\n",
            "44200/44200 [==============================] - 9s 197us/step - loss: 0.3303 - acc: 0.8647 - val_loss: 0.3252 - val_acc: 0.8863\n",
            "Epoch 6/50\n",
            "44200/44200 [==============================] - 9s 197us/step - loss: 0.3059 - acc: 0.8749 - val_loss: 0.3149 - val_acc: 0.8750\n",
            "Epoch 7/50\n",
            "44200/44200 [==============================] - 9s 198us/step - loss: 0.2824 - acc: 0.8846 - val_loss: 0.3412 - val_acc: 0.8787\n",
            "Epoch 8/50\n",
            "44200/44200 [==============================] - 9s 198us/step - loss: 0.2588 - acc: 0.8934 - val_loss: 0.3032 - val_acc: 0.8863\n",
            "Epoch 9/50\n",
            "44200/44200 [==============================] - 9s 196us/step - loss: 0.2375 - acc: 0.9017 - val_loss: 0.3561 - val_acc: 0.8925\n",
            "Epoch 10/50\n",
            "44200/44200 [==============================] - 9s 197us/step - loss: 0.2148 - acc: 0.9095 - val_loss: 0.3411 - val_acc: 0.8762\n",
            "Epoch 11/50\n",
            "44200/44200 [==============================] - 9s 195us/step - loss: 0.2031 - acc: 0.9154 - val_loss: 0.3322 - val_acc: 0.8950\n",
            "Epoch 12/50\n",
            "44200/44200 [==============================] - 9s 198us/step - loss: 0.1873 - acc: 0.9225 - val_loss: 0.3819 - val_acc: 0.8825\n",
            "Epoch 13/50\n",
            "44200/44200 [==============================] - 9s 206us/step - loss: 0.1738 - acc: 0.9273 - val_loss: 0.3259 - val_acc: 0.8950\n",
            "Epoch 14/50\n",
            "44200/44200 [==============================] - 9s 196us/step - loss: 0.1608 - acc: 0.9322 - val_loss: 0.3697 - val_acc: 0.8925\n",
            "Epoch 15/50\n",
            "44200/44200 [==============================] - 9s 195us/step - loss: 0.1553 - acc: 0.9336 - val_loss: 0.4933 - val_acc: 0.8637\n",
            "Epoch 16/50\n",
            "44200/44200 [==============================] - 9s 196us/step - loss: 0.1422 - acc: 0.9409 - val_loss: 0.4143 - val_acc: 0.9012\n",
            "Epoch 17/50\n",
            "44200/44200 [==============================] - 9s 194us/step - loss: 0.1364 - acc: 0.9420 - val_loss: 0.4110 - val_acc: 0.8875\n",
            "Epoch 18/50\n",
            "44200/44200 [==============================] - 9s 194us/step - loss: 0.1325 - acc: 0.9435 - val_loss: 0.4509 - val_acc: 0.8900\n",
            "Epoch 19/50\n",
            "44200/44200 [==============================] - 9s 196us/step - loss: 0.1239 - acc: 0.9470 - val_loss: 0.4848 - val_acc: 0.8900\n",
            "Epoch 20/50\n",
            "44200/44200 [==============================] - 9s 196us/step - loss: 0.1207 - acc: 0.9473 - val_loss: 0.6424 - val_acc: 0.8462\n",
            "Epoch 21/50\n",
            "44200/44200 [==============================] - 9s 194us/step - loss: 0.1174 - acc: 0.9499 - val_loss: 0.5398 - val_acc: 0.8725\n",
            "Epoch 22/50\n",
            "44200/44200 [==============================] - 9s 197us/step - loss: 0.1089 - acc: 0.9528 - val_loss: 0.5082 - val_acc: 0.8875\n",
            "Epoch 23/50\n",
            "44200/44200 [==============================] - 9s 196us/step - loss: 0.1059 - acc: 0.9544 - val_loss: 0.4961 - val_acc: 0.8775\n",
            "Epoch 24/50\n",
            "44200/44200 [==============================] - 9s 197us/step - loss: 0.1060 - acc: 0.9551 - val_loss: 0.5259 - val_acc: 0.8838\n",
            "Epoch 25/50\n",
            "44200/44200 [==============================] - 9s 195us/step - loss: 0.1050 - acc: 0.9551 - val_loss: 0.5714 - val_acc: 0.8863\n",
            "Epoch 26/50\n",
            "44200/44200 [==============================] - 9s 197us/step - loss: 0.1006 - acc: 0.9561 - val_loss: 0.5965 - val_acc: 0.8662\n",
            "Epoch 27/50\n",
            "44200/44200 [==============================] - 9s 196us/step - loss: 0.0982 - acc: 0.9574 - val_loss: 0.5752 - val_acc: 0.8900\n",
            "Epoch 28/50\n",
            "44200/44200 [==============================] - 9s 196us/step - loss: 0.0959 - acc: 0.9579 - val_loss: 0.6246 - val_acc: 0.8800\n",
            "Epoch 29/50\n",
            "44200/44200 [==============================] - 9s 195us/step - loss: 0.0892 - acc: 0.9612 - val_loss: 0.5333 - val_acc: 0.8912\n",
            "Epoch 30/50\n",
            "44200/44200 [==============================] - 9s 195us/step - loss: 0.0919 - acc: 0.9604 - val_loss: 0.5234 - val_acc: 0.8875\n",
            "Epoch 31/50\n",
            "44200/44200 [==============================] - 9s 195us/step - loss: 0.0877 - acc: 0.9616 - val_loss: 0.6029 - val_acc: 0.8950\n",
            "Epoch 32/50\n",
            "44200/44200 [==============================] - 9s 196us/step - loss: 0.0883 - acc: 0.9617 - val_loss: 0.5051 - val_acc: 0.9025\n",
            "Epoch 33/50\n",
            "44200/44200 [==============================] - 9s 195us/step - loss: 0.0855 - acc: 0.9626 - val_loss: 0.5021 - val_acc: 0.9025\n",
            "Epoch 34/50\n",
            "44200/44200 [==============================] - 9s 196us/step - loss: 0.0857 - acc: 0.9626 - val_loss: 1.0113 - val_acc: 0.8413\n",
            "Epoch 35/50\n",
            "44200/44200 [==============================] - 9s 196us/step - loss: 0.0858 - acc: 0.9632 - val_loss: 0.6178 - val_acc: 0.8912\n",
            "Epoch 36/50\n",
            "44200/44200 [==============================] - 9s 196us/step - loss: 0.0840 - acc: 0.9637 - val_loss: 0.6244 - val_acc: 0.8863\n",
            "Epoch 37/50\n",
            "44200/44200 [==============================] - 9s 197us/step - loss: 0.0805 - acc: 0.9654 - val_loss: 0.5672 - val_acc: 0.8950\n",
            "Epoch 38/50\n",
            "44200/44200 [==============================] - 9s 202us/step - loss: 0.0808 - acc: 0.9659 - val_loss: 0.6194 - val_acc: 0.8800\n",
            "Epoch 39/50\n",
            "44200/44200 [==============================] - 9s 195us/step - loss: 0.0787 - acc: 0.9650 - val_loss: 0.6105 - val_acc: 0.8775\n",
            "Epoch 40/50\n",
            "44200/44200 [==============================] - 9s 196us/step - loss: 0.0776 - acc: 0.9662 - val_loss: 0.5628 - val_acc: 0.8912\n",
            "Epoch 41/50\n",
            "44200/44200 [==============================] - 9s 195us/step - loss: 0.0764 - acc: 0.9659 - val_loss: 0.6539 - val_acc: 0.8825\n",
            "Epoch 42/50\n",
            "44200/44200 [==============================] - 9s 195us/step - loss: 0.0764 - acc: 0.9667 - val_loss: 0.6951 - val_acc: 0.8700\n",
            "Epoch 43/50\n",
            "44200/44200 [==============================] - 9s 195us/step - loss: 0.0750 - acc: 0.9675 - val_loss: 0.6096 - val_acc: 0.8988\n",
            "Epoch 44/50\n",
            "44200/44200 [==============================] - 9s 201us/step - loss: 0.0713 - acc: 0.9684 - val_loss: 0.7269 - val_acc: 0.8637\n",
            "Epoch 45/50\n",
            "44200/44200 [==============================] - 10s 235us/step - loss: 0.0781 - acc: 0.9661 - val_loss: 0.6785 - val_acc: 0.8787\n",
            "Epoch 46/50\n",
            "44200/44200 [==============================] - 9s 211us/step - loss: 0.0730 - acc: 0.9679 - val_loss: 0.6546 - val_acc: 0.8888\n",
            "Epoch 47/50\n",
            "44200/44200 [==============================] - 9s 209us/step - loss: 0.0709 - acc: 0.9686 - val_loss: 0.6454 - val_acc: 0.8888\n",
            "Epoch 48/50\n",
            "44200/44200 [==============================] - 9s 207us/step - loss: 0.0698 - acc: 0.9693 - val_loss: 0.6757 - val_acc: 0.8812\n",
            "Epoch 49/50\n",
            " 6400/44200 [===>..........................] - ETA: 7s - loss: 0.0843 - acc: 0.9642"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DFQkdk4KAUyf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}